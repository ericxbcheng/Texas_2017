---
title: "Texas Machine Learning 4: Classification for Fumonisin"
author: "Xianbin Cheng"
date: "12/19/2019"
output: html_document
---

# Objective

  * Train models that can classify kernels by fumonisin levels with high sensitivity and specificity (with sensitivity as the cross validation metric)
  
# Method

1. Read files and load libraries.

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(caret)
library(randomForest)
library(gbm)
library(glmnet)
library(kernlab)
library(MASS)
library(stepPlr)
library(nnet)
library(adabag)
library(kableExtra)
```

```{r, message = FALSE, warning = FALSE}
norm_data = read_csv(file = "tx x_norm_conc_1680_obs.csv")
FM_class = norm_data$FM_class
FM_class[FM_class == "M"] = "H"
spec_data = norm_data %>%
  dplyr::select(-c(X1, Kernel_ID, AF_class, FM_class, Spec_ID_all)) %>%
  as.matrix()

str(norm_data, list.len = 8, give.attr = FALSE)
summary(as.factor(FM_class))
```

2. Train models

  * Train-test split ratio = 7:3
  * Up-sampling of the minority class in the training set
  * 5-fold cross-validation
  * Using "ROC" as a metric for parameter tuning
  * Algorithms:
    - Bagged Adaboost
    - Stochastic gradient boosting
    - Logistic regression with LASSO
    - LDA
    - Random forest
    - Logistic regression with l2 norm
    - SVM with polynomial kernel
    - SVM with radial basis function kernel

```{r}
set.seed(123)
trn_idx = createDataPartition(y = FM_class, p = 0.7, list = FALSE)
trn_data = spec_data[trn_idx, ]
tst_data = spec_data[-trn_idx, ]
trn_FM = FM_class[trn_idx] %>% as.factor()
tst_FM = FM_class[-trn_idx] %>% as.factor()
summary(trn_FM)
summary(tst_FM)

# Up sampling of the minority class
resamp = upSample(x = trn_data, y = trn_FM)
trn_data_samp = dplyr::select(.data = resamp, -Class) %>% as.matrix()
trn_FM_samp = resamp$Class
summary(trn_FM_samp)
```

```{r, echo = FALSE}
rm(spec_data, norm_data, resamp, trn_data_samp)
```

```{r, eval = FALSE}
# TrainControl
cv_5 = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = FALSE)
```

```{r, eval = FALSE}
# Logisitic regression with LASSO
set.seed(123)
cv.mod = cv.glmnet(x = trn_data_samp, y = trn_FM_samp, type.measure = "auc", family = "binomial", alpha = 1)
mod_glmnet = glmnet(x = trn_data_samp, y = trn_FM_samp, family = "binomial", alpha = 1, lambda = cv.mod$lambda.min)
saveRDS(object = mod_glmnet, file = "mod_glmnet_fm_roc.rds")

# gradient stochastic boosting
set.seed(123)
mod_gbm = train(x = trn_data_samp, 
                y = trn_FM_samp, 
                method = "gbm", 
                preProcess = NULL, 
                metric = "ROC", 
                trControl = cv_5, 
                tuneGrid = expand.grid(shrinkage = c(0.01, 0.1), n.minobsinnode = 10, n.trees = c(100, 150, 200), interaction.depth = c(1, 2)))
saveRDS(object = mod_gbm, file = "mod_gbm_fm_roc.rds")

# SVM
set.seed(123)
mod_svm_poly = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "svmPoly", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5)
saveRDS(object = mod_svm_poly, file = "mod_svm_poly_fm_roc.rds")

set.seed(123)
mod_svm_rad = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "svmRadial", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5, 
                    tuneLength = 6)
saveRDS(object = mod_svm_rad, file = "mod_svm_rad_fm_roc.rds")

# Random forest
set.seed(123)
mod_rf = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "rf", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5, 
                    tuneGrid = expand.grid(mtry = c(2, sqrt(ncol(trn_data_samp)), ncol(trn_data_samp) - 1)))
saveRDS(object = mod_rf, file = "mod_rf_fm_roc.rds")

# LDA
set.seed(123)
mod_lda = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "lda", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5)
saveRDS(object = mod_lda, file = "mod_lda_fm_roc.rds")

# penalized logistic regression (l2 norm)
set.seed(123)
mod_logi = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "plr", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5)
saveRDS(object = mod_logi, file = "mod_logi_fm_roc.rds")

# Adabag
set.seed(123)
mod_ada = train(x = trn_data_samp, 
                    y = trn_FM_samp, 
                    method = "AdaBag", 
                    preProcess = NULL, 
                    metric = "ROC", 
                    trControl = cv_5)
saveRDS(object = mod_ada, file = "mod_ada_fm_roc.rds")

##### nnet failed
# set.seed(123)
# mod_nnet = nnet(x = trn_data_samp, y = trn_FM_samp, size = 1, MaxNWts = 1600)

# QDA (collinear variables --> failed)
```

```{r, echo = FALSE}
rds_files = dir(pattern = "fm.rds")
mods = map(.x = rds_files, .f = readRDS)
names(mods) = str_remove(string = rds_files, pattern = ".rds")
```

```{r, echo = FALSE}
get_metrics = function(mod, true){
  
  a = confusionMatrix(data = as.factor(mod), reference = as.factor(true), positive = "H")
  accu = a$overall["Accuracy"]
  sens = a$byClass["Sensitivity"]
  spec = a$byClass["Specificity"]
  return(list(accu, sens, spec))
}

# Plot non-zero beta_hats
get_nonzero = function(model){
  
  a = model$beta %>%
    as.matrix() %>%
    as.data.frame() %>%
    subset(x = ., subset = `s0` != 0)
  
  wavelength = rownames(a) %>% 
    str_remove(string = ., pattern = "X") %>%
    as.numeric()
  
  a$wavelength = wavelength
  colnames(a)[1] = "beta"
  return(a)
}
```

```{r, echo = FALSE, cache = TRUE}
# LASSO with logistic regression
result_glmnet_trn = predict(object = mods$mod_glmnet_fm , newx = trn_data, s = mods$mod_glmnet_fm$lambda, type = "class")
result_glmnet = predict(object = mods$mod_glmnet_fm, newx = tst_data, s = mods$mod_glmnet_fm$lambda, type = "class")

# GBM
result_gbm_trn = predict(object = mods$mod_gbm_fm, newdata = trn_data, type = "raw")
result_gbm = predict(object = mods$mod_gbm_fm, newdata = tst_data, type = "raw")

# SVM polynomial kernel
result_svm_poly_trn = predict(object = mods$mod_svm_poly_fm$finalModel, newdata = trn_data)
result_svm_poly = predict(object = mods$mod_svm_poly_fm$finalModel, newdata = tst_data)

# SVM radial basis kernel
result_svm_rad_trn = predict(object = mods$mod_svm_rad_fm$finalModel, newdata = trn_data)
result_svm_rad = predict(object = mods$mod_svm_rad_fm$finalModel, newdata = tst_data)

# Random forest
result_rf_trn = predict(object = mods$mod_rf_fm$finalModel, newdata = trn_data)
result_rf = predict(object = mods$mod_rf_fm$finalModel, newdata = tst_data)

# LDA
result_lda_trn = predict(object = mods$mod_lda_fm$finalModel, newdata = trn_data)$class
result_lda = predict(object = mods$mod_lda_fm$finalModel, newdata = tst_data)$class

# Logistic regression
result_logi_trn = predict(object = mods$mod_logi_fm, newdata = trn_data)
result_logi = predict(object = mods$mod_logi_fm, newdata = tst_data)

# Ada
result_ada_trn = predict(object = mods$mod_ada_fm, newdata = trn_data)
result_ada = predict(object = mods$mod_ada_fm, newdata = tst_data)
```

# Result

  Training and testing sensitivity and specificity values of each model with tuned parameters are shown here.

```{r, echo = FALSE}
list_trn = list(result_ada_trn, result_gbm_trn, result_glmnet_trn, result_lda_trn, result_logi_trn, result_rf_trn, result_svm_poly_trn, result_svm_rad_trn)
list_tst = list(result_ada, result_gbm, result_glmnet, result_lda, result_logi, result_rf, result_svm_poly, result_svm_rad)

metrics_trn = sapply(X = list_trn, FUN = get_metrics, true = trn_FM)
metrics_tst = sapply(X = list_tst, FUN = get_metrics, true = tst_FM)

get_bestTune = function(model){
  a = model$bestTune
  param = colnames(a)
  return(str_c(param, a, sep = " = ", collapse = ", "))
}

result_table = rbind.data.frame(t(metrics_trn), t(metrics_tst)) %>%
  rename(.data = ., "Accuracy" = "V1", "Sensitivity" = "V2", "Specificity" = "V3") %>%
  mutate(Model = rep(x = c("Ada", "gbm", "LASSO", "LDA", "logistic", "rf", "SVM_poly", "SVM_radial"), times = 2),
         Dataset = rep(x = c("training", "testing"), each = 8), 
         Parameters = rep(x = sapply(X = mods, FUN = get_bestTune), times = 2)) %>%
  dplyr::select(.data = ., c("Model", "Parameters","Dataset", "Accuracy", "Sensitivity", "Specificity")) %>%
  arrange(Model, desc(Dataset))

result_table$Accuracy = unlist(result_table$Accuracy)
result_table$Sensitivity = unlist(result_table$Sensitivity)
result_table$Specificity = unlist(result_table$Specificity)

kable_styling(kable_input = kable(result_table, format = "html", digits = 4), full_width = TRUE)
```

```{r, echo = FALSE}
temp = result_table %>%
  gather(data = ., key = "Metric", value = "Value", -c(Model, Dataset, Parameters))
temp$Value = unlist(temp$Value)

ggplot(data = temp, aes(x = as.factor(Model), y = Value, color = as.factor(Metric))) +
  geom_point() +
  scale_color_discrete(name = "Metric") +
  coord_cartesian(ylim = c(0,1)) +
  facet_grid(as.factor(Dataset) ~ .) +
  labs(x = "Model", "Metric Value") +
  theme_bw()
```

# Conclusion

* The **SVM with radial basis function kernel** model is optimal with a test sensitivity of 0.4643 and a specificity of 0.9389.
* Besides, bagged Adaboost, stochastic gradient boosting, LDA may have the potential to get higher test sensitivity values with the proper tuning.
* Overfitting to the training set is a serious problem.
  
# Appendix

1. The details of parameter tuning of each model are presented here.

```{r, echo = FALSE}
mods$mod_ada_fm
mods$mod_gbm_fm
mods$mod_glmnet_fm
mods$mod_lda_fm
mods$mod_logi_fm
mods$mod_rf_fm
mods$mod_svm_poly_fm
mods$mod_svm_rad_fm
```

2. Reproducibility

```{r, echo = FALSE}
sessionInfo()
```

