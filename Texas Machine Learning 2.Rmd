---
title: "Texas Machine Learning 2"
author: "Xianbin Cheng"
date: "May 11, 2018"
output: html_document
---

## Method ##

1. Load the libraries and read in the files.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(party)
library(doParallel)
```

```{r}
X_Conc = read.csv("TX X_Conc_1008_obs.csv", header = TRUE, row.names = 1)
X_norm_Conc = read.csv("TX X_norm_Conc_1008_obs.csv", header = TRUE, row.names = 1)
```

```{r}
str(X_Conc, list.len = 10)
str(X_norm_Conc, list.len = 10)
```

3. Extract out the texts and labels. Convert the predictor data frame into a matrix. Convert class "M" into "H".

```{r}
AF = X_Conc[ ,"AF_class"] %>% as.character()
FM = X_Conc[ ,"FM_class"] %>% as.character()

summary(as.factor(AF))
summary(as.factor(FM))

AF[which(AF == "M")] = "H" 
FM[which(FM == "M")] = "H" 

AF = as.factor(AF)
FM = as.factor(FM)

summary(AF)
summary(FM)

X = X_Conc %>%
  select(-c(Spec_ID_all, AF_class, FM_class)) %>%
  as.matrix()

X_norm = X_norm_Conc %>%
  select(-c(Spec_ID_all, AF_class, FM_class)) %>%
  as.matrix()
```

```{r}
X[1:5,1:10]
X_norm[1:5, 1:10]
```


2. Exploratory analysis

 - Build a single decision tree to get a sense of which features might be important for classification.
 - Look at the density feature plots for wavelengths that were split on in the decision tree.

```{r}
## Train a single tree model on X_norm to classify aflatoxin level.
class_tree_af = rpart(AF ~ X_norm)

## Train a single tree model on X_norm to classify fumonisin level.
class_tree_fm = rpart(FM ~ X_norm)
```

```{r, echo = FALSE}
rpart.plot(class_tree_af, type = 4, main = "Aflatoxin")
rpart.plot(class_tree_fm, type = 4, main = "Fumonisin")
```

```{r, echo = FALSE, fig.align = "center"}
featurePlot(x = subset(X_norm, select = c(X311, X444, X421)), y = AF, plot = "density", auto.key = TRUE, main = "Aflatoxin")
featurePlot(x = subset(X_norm, select = c(X566, X1029, X419, X401.5, X680, X511.5, X553, X566, X890, X972)), 
            y = FM, plot = "density", auto.key = TRUE, main = "Fumonisin")
```

3. Create a training set and a test set with a test-train split ratio of 25:75.

```{r}
set.seed(123)
trn_ind_af = createDataPartition(y = AF, p = 0.75, list = FALSE)
trn_ind_fm = createDataPartition(y = FM, p = 0.75, list = FALSE)
```

4. We will consider the following method:

* Random forest (`rf`)
    + `mtry` = `r seq(from = 39 -20, to = 39 +20, by = 5)`
    + Calculate 5-fold cross validation error with "ROC" as performance metric
    + Calculate importance

For each method we will consider only one set of features:

* Additive: All 1565 features

We will also consider different types of pre-processing:

* None
* Normalized (centered and scaled)

The model training process will be accelerated by parallelization.

```{r}
cl = makeCluster(detectCores() - 2)
registerDoParallel(cl)
```

```{r}
mtry_chosen = floor(sqrt(ncol(X)))
cv_5 = trainControl(method = "cv",
                    number = 5,
                    classProbs = TRUE,
                    summaryFunction = twoClassSummary,
                    allowParallel = TRUE)
```

```{r, eval = FALSE}
## Pre-processing: None
set.seed(123)
mod_rf_af = train(x = X[trn_ind_af, ], 
                  y = AF[trn_ind_af],
                  xtest = X[-trn_ind_af, ],
                  ytest = AF[-trn_ind_af],
                  method = "rf", 
                  importance = TRUE,
                  keep.forest = TRUE,
                  metric = "ROC",
                  trControl = cv_5,
                  tuneGrid = expand.grid(mtry = seq(from = mtry_chosen - 20, to = mtry_chosen + 20, by = 5))
)

set.seed(123)
mod_rf_fm = train(x = X[trn_ind_fm, ],
                  y = FM[trn_ind_fm],
                  xtest = X[-trn_ind_fm, ],
                  ytest = FM[-trn_ind_fm],
                  method = "rf",
                  importance = TRUE,
                  keep.forest = TRUE,
                  metric = "ROC",
                  trControl = cv_5,
                  tuneGrid = expand.grid(mtry = seq(from = mtry_chosen - 20, to = mtry_chosen + 20, by = 5))
)
```

```{r, eval = FALSE}
## Pre-processing: Normalized
set.seed(123)
mod_rf_norm_af = train(x = X_norm[trn_ind_af, ], 
                  y = AF[trn_ind_af],
                  xtest = X_norm[-trn_ind_af, ],
                  ytest = AF[-trn_ind_af],
                  method = "rf", 
                  importance = TRUE,
                  keep.forest = TRUE,
                  metric = "ROC",
                  trControl = cv_5,
                  tuneGrid = expand.grid(mtry = seq(from = mtry_chosen - 20, to = mtry_chosen + 20, by = 5))
)

set.seed(123)
mod_rf_norm_fm = train(x = X_norm[trn_ind_fm, ],
                  y = FM[trn_ind_fm],
                  xtest = X_norm[-trn_ind_fm, ],
                  ytest = FM[-trn_ind_fm],
                  method = "rf",
                  importance = TRUE,
                  keep.forest = TRUE,
                  metric = "ROC",
                  trControl = cv_5,
                  tuneGrid = expand.grid(mtry = seq(from = mtry_chosen - 20, to = mtry_chosen + 20, by = 5))
)
```

```{r, echo = FALSE}
mod_rf_af = readRDS("mod_rf_af.rds")
mod_rf_fm = readRDS("mod_rf_fm.rds")
mod_rf_norm_af = readRDS("mod_rf_norm_af.rds")
mod_rf_norm_fm = readRDS("mod_rf_norm_fm.rds")
```


## Result ##

1. Show the classification error rate for all the models as well as the cross validatio ROC plot for tuning `mtry`.

```{r}
plot_sens_spec = function(model){
  df = model$results %>%
    select(mtry, ROC, Sens, Spec) %>%
    gather(data = ., key = "Type", value = "Value", -mtry)
  
  ggplot(data = df, aes(x = mtry, y = Value, color = Type)) +
    geom_line() +
    geom_point() +
    theme_bw()
}
```

```{r, fig.width = 5, fig.height = 3}
## Transformation: none. Classification: Aflatoxin.
mod_rf_af$finalModel
plot_sens_spec(mod_rf_af)

## Transformation: none. Classification: Fumonisin.
mod_rf_fm$finalModel
plot_sens_spec(mod_rf_fm)

## Transformation: normalized. Classification: Aflatoxin.
mod_rf_norm_af$finalModel
plot_sens_spec(mod_rf_norm_af)

## Transformation: normalized. Classification: Fumonisin.
mod_rf_norm_fm$finalModel
plot_sens_spec(mod_rf_norm_fm)
```

2. Show the importance plots.

```{r}
## Create a function for visualizing mean decrease in accuracy.
MDA = function(model){
  a = importance(model) %>% as.data.frame()
  wl = gsub(pattern = "X", replacement = "", x = rownames(a)) %>% as.numeric()
  
  ggplot(data = a) +
    geom_point(aes(x = wl, y = a$MeanDecreaseAccuracy, color = a$MeanDecreaseAccuracy)) +
    scale_color_gradient(low="grey", high="darkgreen", name="") +
    labs(x="Wavelength (nm)", y="Mean Decrease in Accuracy") +
    theme_bw()
}
```

```{r}
## Transformation: none. Classification: Aflatoxin.
MDA(mod_rf_af$finalModel)

## Transformation: none. Classification: Fumonisin.
MDA(mod_rf_fm$finalModel)

## Transformation: normalized. Classification: Aflatoxin.
MDA(mod_rf_norm_af$finalModel)

## Transformation: normalized. Classification: Fumonisin.
MDA(mod_rf_norm_fm$finalModel)
```
